{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98bff7e-866e-422f-88d6-03978532e978",
   "metadata": {},
   "source": [
    "# Extra Notes for Bagging and Random Forest (Base)\n",
    "\n",
    "**Ensemble Learning Focus:** This assessment emphasizes understanding how bagging and Random Forest improve upon single decision trees through variance reduction and aggregation of multiple learners.\n",
    "\n",
    "**Feature Selection Strategy:** Using Random Forest for feature selection is generally more robust than using a single decision tree because it averages importance scores across many trees, reducing the impact of any single tree's idiosyncrasies.\n",
    "\n",
    "**Feature Importance:** Pay attention to how Random Forest's feature importance (averaged over many trees) differs from a single tree's importance. This reveals which features are consistently important vs. those that vary with specific tree structures.\n",
    "\n",
    "**Performance vs. Interpretability:** While ensemble methods often outperform single trees, they sacrifice some interpretability. Linear models (LPM, Logistic) offer the most interpretability through coefficients. Consider this trade-off carefully in your recommendation.\n",
    "\n",
    "**Computational Considerations:** Random Forest and Bagging train multiple trees (100 in this case), which requires more computation than single models. However, predictions can be parallelized, making them feasible for production use.\n",
    "\n",
    "**Comparison Strategy:** Use consistent evaluation criteria across all models. The 0.5 threshold is standard, but in practice, this threshold could be adjusted based on the relative costs of Type I vs. Type II errors.\n",
    "\n",
    "**Training Accuracy:** Be cautious when interpreting training accuracy. Higher training accuracy doesn't always mean better generalization. Look for the balance between training and test performance.\n",
    "\n",
    "**Cost-Sensitive Learning:** In the income prediction context, consider which error is more costly: falsely predicting someone earns `>$50K` (Type I) or falsely predicting someone earns `<=$50K` (Type II). This consideration should inform your model recommendation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
